{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chadi/anaconda3/envs/tensorflow3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "I0226 17:38:34.418381 139661789845248 file_utils.py:39] PyTorch version 1.3.0 available.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from passage_reader import get_passages_for_relations, get_passages_for_relations_selective_negative\n",
    "from  transformers import DistilBertTokenizer, DistilBertModel, DistilBertForSequenceClassification, AdamW\n",
    "from  transformers import BertTokenizer, BertModel, BertForSequenceClassification, BertPreTrainedModel\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rerank_passages import qid_relation, read_passages, get_query, tokenizer as nltk_tokenizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import operator\n",
    "import rank_bm25\n",
    "import nltk\n",
    "import pickle\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "# from apex import amp\n",
    "from random import random\n",
    "from copy import deepcopy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = ['actedIn', 'created', 'diedIn', 'diedOnDate', 'directed', 'graduatedFrom', 'hasCapital', 'hasChild',\n",
    "             'hasWonPrize', 'influences', 'isCitizenOf', 'isKnownFor', 'isLeaderOf', 'isLocatedIn', 'isMarriedTo',\n",
    "             'isPoliticianOf', 'participatedIn', 'wasBornIn', 'wasBornOnDate']\n",
    "\n",
    "instance_converter = {'actedIn':'acted in', 'created': 'created', 'diedIn': 'died in', 'diedOnDate': 'died on date', 'directed':'directed', 'graduatedFrom':'graduated from', 'hasCapital': 'has capital', 'hasChild': 'has child',\n",
    "             'hasWonPrize': 'has won prize','influences': 'influences','isCitizenOf': 'is citizen of', 'isKnownFor': 'is known for', 'isLeaderOf': 'is leader of', 'isLocatedIn': 'is located in', 'isMarriedTo': 'is married to',\n",
    "             'isPoliticianOf': 'is politician of', 'participatedIn': 'participated in', 'wasBornIn': 'was born in', 'wasBornOnDate': 'was born on date'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASSAGE_DIRECTORY = 'passages/fact_check_centroid_sorted'\n",
    "SAMPLE_SIZE = 4000\n",
    "SKIP_DUPLICATE = True\n",
    "REGRESSION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_entities(passage, source, target, label=None):\n",
    "    \n",
    "    passage = passage.replace('(', ' ( ')\n",
    "    passage = passage.replace(')', ' ) ')\n",
    "    passage = passage.replace('[', ' [ ')\n",
    "    passage = passage.replace(']', ' ] ')\n",
    "    passage = passage.replace('  ', ' ')\n",
    "    \n",
    "    passage = passage.replace(source, '<startSource> {} <endSource>'.format(source))\n",
    "    passage = passage.replace(target, '<startTarget> {} <endTarget>'.format(target))\n",
    "    list_stopwords = set(stopwords.words('english'))\n",
    "    subjects = []\n",
    "    objects = []\n",
    "    for w in source.split(' '):\n",
    "        if w.lower() not in list_stopwords:\n",
    "            subjects.append(w)\n",
    "    \n",
    "    for w in target.split(' '):\n",
    "        if w.lower() not in list_stopwords:\n",
    "            objects.append(w)\n",
    "    \n",
    "    reg_split = re.compile(r'[\\s\\.\\,\\!\\?\\:\\;/-]')\n",
    "    source_start = False\n",
    "    target_start = False  \n",
    "    tagged_passage = ''\n",
    "\n",
    "    for w in reg_split.split(passage):\n",
    "        w = w.strip()\n",
    "        if not source_start and w == '<startSource>':      \n",
    "            source_start = True\n",
    "            tagged_passage += ' {} '.format(w)\n",
    "        elif source_start and w == '<endSource>':\n",
    "            source_start = False\n",
    "            tagged_passage += ' {} '.format(w)\n",
    "        elif not target_start and w == '<startTarget>':\n",
    "            target_start = True\n",
    "            tagged_passage += ' {} '.format(w)\n",
    "        elif target_start and w == '<endTarget>':\n",
    "            target_start = False\n",
    "            tagged_passage += ' {} '.format(w)\n",
    "        elif not source_start and not target_start:\n",
    "            if w in subjects:\n",
    "                tagged_passage += ' <startSource> {} <endSource> '.format(w)\n",
    "            elif w in objects:\n",
    "                tagged_passage += ' <startTarget> {} <endTarget> '.format(w)\n",
    "            else:\n",
    "                tagged_passage += ' {} '.format(w)\n",
    "        else:\n",
    "            tagged_passage += ' {} '.format(w)\n",
    "        \n",
    "    return tagged_passage.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, label = get_passages_for_relations_selective_negative(directory=PASSAGE_DIRECTORY, relations=instances,\n",
    "                                                               sample_size=SAMPLE_SIZE,\n",
    "                                                               # skip_mode='even',  # skip even line\n",
    "                                                               skip_duplicate=SKIP_DUPLICATE,\n",
    "                                                               regression=REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tag_entities(data['passage'][29] + 'Jane '+'Thomas', data['source'][29], data['target'][29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['converted_relation'] = data['relation'].apply(lambda x: instance_converter[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['source_relation_target'] = data['source'] +' ' + data['converted_relation'] + ' ' + data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bm25_sentences(paragraph, query):\n",
    "    sentences = nltk.sent_tokenize(paragraph.replace('.', ' . '))\n",
    "    tokenized_sentences = []\n",
    "        \n",
    "    for s in sentences:\n",
    "        tokenized_sentences.append(nltk_tokenizer.tokenize(s))\n",
    "            \n",
    "    bm25 = BM25Okapi(tokenized_sentences)\n",
    "    tokenized_query = nltk_tokenizer.tokenize(query)\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "        \n",
    "    merge_sentences_scores = list(zip(sentences, bm25_scores))\n",
    "   \n",
    "    merge_sentences_scores.sort(key=lambda tup: tup[1], reverse=True)\n",
    "   \n",
    "    sorted_sentences = [s for s, score in merge_sentences_scores[:3]]\n",
    "        \n",
    "    if len(sorted_sentences) < 3:\n",
    "        sorted_sentences+=[' '] * (3-len(sorted_sentences))\n",
    "    \n",
    "    sorted_length_sentences = sorted_sentences.copy()\n",
    "    \n",
    "    length_sentences = [len(x.split(' ')) for x in sorted_sentences]\n",
    "    sorted_length_sentences += length_sentences\n",
    "    \n",
    "    return tuple(sorted_length_sentences)\n",
    "    \n",
    "#paragraph 51120\n",
    "# print(compute_bm25_sentences(data['passage'][37], data['source_relation_target'][37]))\n",
    "# label[10]\n",
    "# print(data['source_relation_target'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disjoint_ngrams(sentence, n):\n",
    "    tokenized_sentence = sentence.split(' ')\n",
    "    divide_sentence = int(len(tokenized_sentence)/n)\n",
    "    ngram_sentences = []\n",
    "    begin = 0\n",
    "    end = n\n",
    "    for _ in range(0, divide_sentence):\n",
    "        print(tokenized_sentence[begin:end])\n",
    "        ngram_sentences.append(tokenized_sentence[begin:end])\n",
    "        begin = end\n",
    "        end += n\n",
    "    return ngram_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bm25_sentences_with_n_grams(paragraph, query):\n",
    "#     sentences = nltk_tokenizer.tokenize(paragraph)\n",
    "    tokenized_sentences = disjoint_ngrams(paragraph,20)\n",
    "#     for s in ngrams(sentences,6):\n",
    "#         tokenized_sentences.append(s)\n",
    "    \n",
    "    bm25 = BM25Okapi(tokenized_sentences)\n",
    "    tokenized_query = nltk_tokenizer.tokenize(query)\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_loss(s_i, s_j, S_ij, sigma=1):\n",
    "    C = torch.log1p(torch.exp(-sigma * (s_i - s_j)))\n",
    "    if S_ij == -1:\n",
    "        C += sigma * (s_i - s_j)\n",
    "    elif S_ij == 0:\n",
    "        C += 0.5 * sigma * (s_i - s_j)\n",
    "    elif S_ij == 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"S_ij: -1/0/1\")\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentence_1'], data['sentence_2'], data['sentence_3'], data['length_1'], data['length_2'], data['length_3']  = zip(*data.apply(lambda x: compute_bm25_sentences(x['passage'], x['source_relation_target']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['sentence_1'][10], data['sentence_2'][10], data['sentence_3'][10])\n",
    "print(data['passage'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "special_tokens_dict = {'additional_special_tokens':['<startSource>', '<endSource>', \n",
    "                                                    '<startTarget>','<endTarget>']}\n",
    "print(len(bert_tokenizer))\n",
    "num_added_tokens = bert_tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print('{} special tokens were added'.format(num_added_tokens))\n",
    "print(len(bert_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_x_y_sentences(tokenizer, data, label):\n",
    "    y = []\n",
    "    \n",
    "    x_1 = []\n",
    "    x_1_tokens = []\n",
    "    segment_id_1 = []\n",
    "    attention_mask_1 = []\n",
    "    \n",
    "    x_2 = []\n",
    "    x_2_tokens = []\n",
    "    segment_id_2 = []\n",
    "    attention_mask_2 = []\n",
    "    \n",
    "    x_3 = []\n",
    "    x_3_tokens = []\n",
    "    segment_id_3 = []\n",
    "    attention_mask_3 = []\n",
    "\n",
    "    for s_1, s_2, s_3, src, targ, r, l in zip(data['sentence_1'], data['sentence_2'], data['sentence_3'],\n",
    "                       data['source'], data['target'], data['source_relation_target'], label):\n",
    "        \n",
    "        s_1 = tag_entities(passage=s_1, source=src, target=targ)\n",
    "        s_2 = tag_entities(passage=s_2, source=src, target=targ)\n",
    "        s_3 = tag_entities(passage=s_3, source=src, target=targ)\n",
    "        \n",
    "        temp_x_1, temp_x_1_tokens, temp_segment_id_1, temp_attention_mask_1 = transform_passage(tokenizer, s_1, r)\n",
    "        temp_x_2, temp_x_2_tokens, temp_segment_id_2, temp_attention_mask_2 = transform_passage(tokenizer, s_2, r)\n",
    "        temp_x_3, temp_x_3_tokens, temp_segment_id_3, temp_attention_mask_3 = transform_passage(tokenizer, s_3, r)\n",
    "        \n",
    "        if temp_x_1 is not None and temp_x_2 is not None and temp_x_3 is not None:\n",
    "            x_1.append(temp_x_1)\n",
    "            x_1_tokens.append(temp_x_1_tokens)\n",
    "            segment_id_1.append(temp_segment_id_1)\n",
    "            attention_mask_1.append(temp_attention_mask_1)\n",
    "            \n",
    "            x_2.append(temp_x_2)\n",
    "            x_2_tokens.append(temp_x_2_tokens)\n",
    "            segment_id_2.append(temp_segment_id_2)\n",
    "            attention_mask_2.append(temp_attention_mask_2)\n",
    "            \n",
    "            x_3.append(temp_x_3)\n",
    "            x_3_tokens.append(temp_x_3_tokens)\n",
    "            segment_id_3.append(temp_segment_id_3)\n",
    "            attention_mask_3.append(temp_attention_mask_3)\n",
    "            \n",
    "            y.append(l)\n",
    "            \n",
    "    return x_1, x_1_tokens, segment_id_1, attention_mask_1,\\\n",
    "        x_2, x_2_tokens, segment_id_2, attention_mask_2,\\\n",
    "        x_3, x_3_tokens, segment_id_3, attention_mask_3,\\\n",
    "        y\n",
    "        \n",
    "def transform_data_x_sentences(tokenizer, passages, relations, sources, targets):\n",
    "    x_1 = []\n",
    "    x_1_tokens = []\n",
    "    segment_id_1 = []\n",
    "    attention_mask_1 = []\n",
    "    \n",
    "    x_2 = []\n",
    "    x_2_tokens = []\n",
    "    segment_id_2 = []\n",
    "    attention_mask_2 = []\n",
    "    \n",
    "    x_3 = []\n",
    "    x_3_tokens = []\n",
    "    segment_id_3 = []\n",
    "    attention_mask_3 = []\n",
    "\n",
    "    for p, rel, src, targ in zip(passages, relations, sources, targets):\n",
    "        \n",
    "        source_relation_target = src + ' ' + rel + ' ' + targ\n",
    "        \n",
    "        s_1, s_2, s_3, _, _, _ =  compute_bm25_sentences(p, source_relation_target)\n",
    "        \n",
    "        s_1 = tag_entities(passage=s_1, source=src, target=targ)\n",
    "        s_2 = tag_entities(passage=s_2, source=src, target=targ)\n",
    "        s_3 = tag_entities(passage=s_3, source=src, target=targ)\n",
    "        \n",
    "        temp_x_1, temp_x_1_tokens, temp_segment_id_1, temp_attention_mask_1 = transform_passage(tokenizer, s_1,\\\n",
    "                                                                                                source_relation_target)\n",
    "        temp_x_2, temp_x_2_tokens, temp_segment_id_2, temp_attention_mask_2 = transform_passage(tokenizer, s_2,\\\n",
    "                                                                                                source_relation_target)\n",
    "        temp_x_3, temp_x_3_tokens, temp_segment_id_3, temp_attention_mask_3 = transform_passage(tokenizer, s_3,\\\n",
    "                                                                                                source_relation_target)\n",
    "        \n",
    "        x_1.append(temp_x_1)\n",
    "        x_1_tokens.append(temp_x_1_tokens)\n",
    "        segment_id_1.append(temp_segment_id_1)\n",
    "        attention_mask_1.append(temp_attention_mask_1)\n",
    "            \n",
    "        x_2.append(temp_x_2)\n",
    "        x_2_tokens.append(temp_x_2_tokens)\n",
    "        segment_id_2.append(temp_segment_id_2)\n",
    "        attention_mask_2.append(temp_attention_mask_2)\n",
    "            \n",
    "        x_3.append(temp_x_3)\n",
    "        x_3_tokens.append(temp_x_3_tokens)\n",
    "        segment_id_3.append(temp_segment_id_3)\n",
    "        attention_mask_3.append(temp_attention_mask_3)\n",
    "\n",
    "    return x_1, x_1_tokens, segment_id_1, attention_mask_1,\\\n",
    "        x_2, x_2_tokens, segment_id_2, attention_mask_2,\\\n",
    "        x_3, x_3_tokens, segment_id_3, attention_mask_3\n",
    "\n",
    "def transform_passage(tokenizer, passage, relation):\n",
    "    max_length = 300\n",
    "    tokenized_r = tokenizer.tokenize(relation)\n",
    "    tokenized_p = tokenizer.tokenize(passage)[:max_length - len(tokenized_r) - 3]\n",
    "    \n",
    "    if len(tokenized_p) + len(tokenized_r) < max_length: #509\n",
    "        temp_x = ['[CLS]'] + tokenized_p + ['[SEP]'] + tokenized_r + ['[SEP]']\n",
    "        temp_segment_id = (len(tokenized_p)+2) * [0] + (len(tokenized_r)+1) * [1] + (max_length - len(temp_x)) * [0]\n",
    "        temp_attention_mask = (len(tokenized_p)+2) * [1] + (len(tokenized_r)+1) * [1] + (max_length - len(temp_x)) * [0]\n",
    "        x_tokens = np.asarray(tokenizer.convert_tokens_to_ids(temp_x) + (max_length - len(temp_x)) * [0])\n",
    "        return temp_x, x_tokens, temp_segment_id, temp_attention_mask\n",
    "    \n",
    "    return (None,) * 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, x_tokens, segment_id, attention_mask, y = transform_data_x_y(bert_tokenizer, data, label)\n",
    "x_1, x_1_tokens, segment_id_1, attention_mask_1,\\\n",
    "    x_2, x_2_tokens, segment_id_2, attention_mask_2,\\\n",
    "    x_3, x_3_tokens, segment_id_3, attention_mask_3,\\\n",
    "    y = transform_data_x_y_sentences(bert_tokenizer, data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_3[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, x_tokens, segment_id, attention_mask, y):\n",
    "    x_tokens_train, x_tokens_val, y_train, y_val = train_test_split(x_tokens, y, test_size=0.1, random_state=42)\n",
    "    _, _, segment_id_train, segment_id_val = train_test_split(x_tokens, segment_id, test_size=0.1, random_state=42)\n",
    "    _, _, attention_mask_train, attention_mask_val = train_test_split(x_tokens, attention_mask, test_size=0.1, random_state=42)\n",
    "    _, _, x_train, x_val = train_test_split(x_tokens, x, test_size=0.1, random_state=42)\n",
    "    \n",
    "    return x_train, x_tokens_train, segment_id_train, attention_mask_train, y_train,\\\n",
    "        x_val, x_tokens_val, segment_id_val, attention_mask_val, y_val \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_train, x_1_tokens_train, segment_id_1_train,\\\n",
    "    attention_mask_1_train, y_1_train,\\\n",
    "    x_1_val, x_1_tokens_val, segment_id_1_val,\\\n",
    "    attention_mask_1_val, y_1_val = split_data(x_1, x_1_tokens, segment_id_1, attention_mask_1, y)\n",
    "    \n",
    "\n",
    "x_2_train, x_2_tokens_train, segment_id_2_train,\\\n",
    "    attention_mask_2_train, y_2_train,\\\n",
    "    x_2_val, x_2_tokens_val, segment_id_2_val,\\\n",
    "    attention_mask_2_val, y_2_val = split_data(x_2, x_2_tokens, segment_id_2, attention_mask_2, y)\n",
    "    \n",
    "x_3_train, x_3_tokens_train, segment_id_3_train,\\\n",
    "    attention_mask_3_train, y_3_train,\\\n",
    "    x_3_val, x_3_tokens_val, segment_id_3_val,\\\n",
    "    attention_mask_3_val, y_3_val = split_data(x_3, x_3_tokens, segment_id_3, attention_mask_3, y)\n",
    "    \n",
    "print(x_1_train[10])\n",
    "print(x_2_train[10])\n",
    "print(x_3_train[10])\n",
    "\n",
    "print('')\n",
    "print(x_1_val[10])\n",
    "print(x_2_val[10])\n",
    "print(x_3_val[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor_train_val(x_tokens_train, segment_id_train, attention_mask_train, y_train,\\\n",
    "                      x_tokens_val, segment_id_val, attention_mask_val, y_val):\n",
    "\n",
    "    x_tokens_train_tensor, segment_id_train_tensor, attention_mask_train_tensor = convert_to_tensor_x(x_tokens_train,\\\n",
    "                                                                                                      segment_id_train, attention_mask_train)\n",
    "    y_train_tensor = torch.tensor(y_train)\n",
    "\n",
    "    x_tokens_val_tensor, segment_id_val_tensor, attention_mask_val_tensor = convert_to_tensor_x(x_tokens_val,\\\n",
    "                                                                                                segment_id_val, attention_mask_val)\n",
    "    y_val_tensor = torch.tensor(y_val)\n",
    "    \n",
    "    return x_tokens_train_tensor, segment_id_train_tensor,\\\n",
    "        attention_mask_train_tensor, y_train_tensor,\\\n",
    "        x_tokens_val_tensor, segment_id_val_tensor,\\\n",
    "        attention_mask_val_tensor, y_val_tensor\n",
    "\n",
    "def convert_to_tensor_x(x_tokens, segment_id, attention_mask):\n",
    "    x_tokens_tensor = torch.tensor(x_tokens)\n",
    "    segment_id_tensor = torch.tensor(segment_id)\n",
    "    attention_mask_tensor = torch.tensor(attention_mask)\n",
    "    \n",
    "    return x_tokens_tensor, segment_id_tensor, attention_mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_tokens_train_tensor, segment_id_1_train_tensor,\\\n",
    "    attention_mask_1_train_tensor, y_1_train_tensor,\\\n",
    "    x_1_tokens_val_tensor, segment_id_1_val_tensor, \\\n",
    "    attention_mask_val_1_tensor, y_val_1_tensor = convert_to_tensor_train_val(x_1_tokens_train, segment_id_1_train,\\\n",
    "                                                                    attention_mask_1_train, y_1_train,\\\n",
    "                                                                    x_1_tokens_val, segment_id_1_val,\\\n",
    "                                                                    attention_mask_1_val, y_1_val)\n",
    "    \n",
    "x_2_tokens_train_tensor, segment_id_2_train_tensor,\\\n",
    "    attention_mask_2_train_tensor, y_2_train_tensor,\\\n",
    "    x_2_tokens_val_tensor, segment_id_2_val_tensor, \\\n",
    "    attention_mask_val_2_tensor, y_val_2_tensor = convert_to_tensor_train_val(x_2_tokens_train, segment_id_2_train,\\\n",
    "                                                                    attention_mask_2_train, y_2_train,\\\n",
    "                                                                    x_2_tokens_val, segment_id_2_val,\\\n",
    "                                                                    attention_mask_2_val, y_2_val)\n",
    "    \n",
    "x_3_tokens_train_tensor, segment_id_3_train_tensor,\\\n",
    "    attention_mask_3_train_tensor, y_3_train_tensor,\\\n",
    "    x_3_tokens_val_tensor, segment_id_3_val_tensor, \\\n",
    "    attention_mask_val_3_tensor, y_val_3_tensor = convert_to_tensor_train_val(x_3_tokens_train, segment_id_3_train,\\\n",
    "                                                                    attention_mask_3_train, y_3_train,\\\n",
    "                                                                    x_3_tokens_val, segment_id_3_val,\\\n",
    "                                                                    attention_mask_3_val, y_3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEntityBertModel(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(SentenceEntityBertModel, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.last_hidden_layer = torch.nn.Linear(config.hidden_size, 150)\n",
    "        self.last_hidden_layer_1 = torch.nn.Linear(150*3, 150)\n",
    "        self.classifier = torch.nn.Linear(150, self.config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward_once(self, input_ids, token_type_ids=None, attention_mask=None,\n",
    "                position_ids=None, head_mask=None, labels=None):\n",
    "\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            position_ids=position_ids, \n",
    "                            head_mask=head_mask)\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        last_hidden_layer = self.last_hidden_layer(pooled_output)\n",
    "        \n",
    "        return last_hidden_layer\n",
    "    \n",
    "    def forward(self, input_ids_1, token_type_ids_1, attention_mask_1,\\\n",
    "                input_ids_2, token_type_ids_2, attention_mask_2,\\\n",
    "                input_ids_3, token_type_ids_3, attention_mask_3,\\\n",
    "                labels=None):\n",
    "        global device\n",
    "        \n",
    "        last_hidden_layer_1  = self.forward_once(input_ids=input_ids_1.to(device), token_type_ids=token_type_ids_1.to(device), attention_mask=attention_mask_1.to(device))\n",
    "        last_hidden_layer_2  = self.forward_once(input_ids=input_ids_2.to(device), token_type_ids=token_type_ids_2.to(device), attention_mask=attention_mask_2.to(device))\n",
    "        last_hidden_layer_3  = self.forward_once(input_ids=input_ids_3.to(device), token_type_ids=token_type_ids_3.to(device), attention_mask=attention_mask_3.to(device))\n",
    "        \n",
    "        my_tensor = torch.cat((last_hidden_layer_1, last_hidden_layer_2, last_hidden_layer_3), dim=1)\n",
    "\n",
    "        output_hidden_layer_1 = self.last_hidden_layer_1(my_tensor)\n",
    "        logits = self.classifier(output_hidden_layer_1)\n",
    "        \n",
    "        outputs = (logits,) # + outputs[2:]   add hidden states and attention if they are here\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "training_tensors = TensorDataset(x_1_tokens_train_tensor, segment_id_1_train_tensor, attention_mask_1_train_tensor,\\\n",
    "                                     x_2_tokens_train_tensor, segment_id_2_train_tensor, attention_mask_2_train_tensor,\\\n",
    "                                     x_3_tokens_train_tensor, segment_id_3_train_tensor, attention_mask_3_train_tensor,\\\n",
    "                                     y_3_train_tensor)\n",
    "    \n",
    "val_tensors = TensorDataset(x_1_tokens_val_tensor, segment_id_1_val_tensor, attention_mask_val_1_tensor,\\\n",
    "                                x_2_tokens_val_tensor, segment_id_2_val_tensor, attention_mask_val_2_tensor,\\\n",
    "                                x_3_tokens_val_tensor, segment_id_3_val_tensor, attention_mask_val_3_tensor,\\\n",
    "                                y_val_3_tensor)\n",
    "    \n",
    "training_set = DataLoader(training_tensors, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
    "val_set = DataLoader(val_tensors, batch_size=128, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_passages(bert_tokenizer, nltk_tokenizer, model, passages, relations, sources, targets, query_text):\n",
    "    global device\n",
    "    model.to(device)\n",
    "    \n",
    "    rank_scores = np.zeros(shape=(len(passages), 2))\n",
    "    bm25_scores = np.zeros(shape=(len(passages), 2))\n",
    "\n",
    "    for relation, source, target in zip(relations, sources, targets):\n",
    "\n",
    "        relation = [relation] * len(passages)\n",
    "        source = [source] * len(passages)\n",
    "        target = [target] * len(passages)\n",
    "        \n",
    "        passtext = [passage.text for passage in passages]\n",
    "\n",
    "        x_1_test, x_1_tokens_test, segment_id_1_test, attention_mask_1_test,\\\n",
    "        x_2_test, x_2_tokens_test, segment_id_2_test, attention_mask_2_test,\\\n",
    "        x_3_test, x_3_tokens_test, segment_id_3_test, attention_mask_3_test = transform_data_x_sentences(bert_tokenizer,\\\n",
    "                                                                                                         passtext, relation, source, target)\n",
    "        \n",
    "        x_1_tokens_test_tensor, segment_id_1_test_tensor, attention_mask_1_test_tensor = convert_to_tensor_x(x_1_tokens_test,\\\n",
    "                                                                                                             segment_id_1_test, attention_mask_1_test)\n",
    "        x_2_tokens_test_tensor, segment_id_2_test_tensor, attention_mask_2_test_tensor = convert_to_tensor_x(x_2_tokens_test,\\\n",
    "                                                                                                             segment_id_2_test, attention_mask_2_test)\n",
    "        x_3_tokens_test_tensor, segment_id_3_test_tensor, attention_mask_3_test_tensor = convert_to_tensor_x(x_3_tokens_test,\\\n",
    "                                                                                                             segment_id_3_test, attention_mask_3_test) \n",
    "        temp_rank_scores = []\n",
    "#         print(x_1_test[0])\n",
    "#         print(x_1_tokens_test[0])\n",
    "#         print(segment_id_1_test[0])\n",
    "#         print(attention_mask_1_test[0])\n",
    "        test_tensors = TensorDataset(x_1_tokens_test_tensor, segment_id_1_test_tensor, attention_mask_1_test_tensor,\\\n",
    "                                     x_2_tokens_test_tensor, segment_id_2_test_tensor, attention_mask_2_test_tensor,\\\n",
    "                                     x_3_tokens_test_tensor, segment_id_3_test_tensor, attention_mask_3_test_tensor)\n",
    "        test_set = DataLoader(test_tensors, batch_size=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (in_1, seg_1, attn_1, in_2, seg_2, attn_2, in_3, seg_3, attn_3) in enumerate(test_set):\n",
    "#                 print((in_1, seg_1, attn_1, in_2, seg_2, attn_2, in_3, seg_3, attn_3))\n",
    "                results = model(in_1, seg_1, attn_1, in_2, seg_2, attn_2, in_3, seg_3, attn_3)\n",
    "                temp_rank_scores.append(results[0].cpu().detach().numpy()[0])\n",
    "            rank_scores += np.asarray(temp_rank_scores)\n",
    "        \n",
    "#         tokenized_corpus = []\n",
    "\n",
    "#         for p in passtext:\n",
    "#             tokenized_corpus.append(nltk_tokenizer.tokenize(p))\n",
    "# #         # bm25\n",
    "# #         # tokenized_corpus = tokenizer.tokenize(passtext)\n",
    "#         bm25 = BM25Okapi(tokenized_corpus)\n",
    "#         tokenized_query = nltk_tokenizer.tokenize(query_text)\n",
    "#         bm25_scores[:, 0] = bm25.get_scores(tokenized_query)\n",
    "#         rank_scores += bm25_scores\n",
    "    rank_scores /= (len(relations) * 2)\n",
    "\n",
    "    for i, score in enumerate(rank_scores):\n",
    "       \n",
    "        passages[i].score = score[0]\n",
    "\n",
    "    passages.sort(key=operator.attrgetter('score'), reverse=True)\n",
    "    return passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_labels = 2\n",
    "\n",
    "model = SentenceEntityBertModel.from_pretrained('bert-base-cased', num_labels=num_labels)\n",
    "model.resize_token_embeddings(len(bert_tokenizer))\n",
    "model.to(device)\n",
    "\n",
    "FULL_FINETUNE = True\n",
    "\n",
    "optimizer_grouped_parameters = None\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "\n",
    "if FULL_FINETUNE:\n",
    "    print('ALL FINETUNE')\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    print('NO ALL FINETUNE')\n",
    "    #         {'params': model.last_hidden_layer.parameters(),\n",
    "#          'weight_decay_rate': 0.01},\n",
    "\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': model.classifier.parameters(),\n",
    "         'weight_decay_rate': 0.01}\n",
    "    ]\n",
    "\n",
    "for n, p in param_optimizer:\n",
    "    print(n)\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
    "# model, optimizer = amp.initialize(model, optimizer, opt_level='O0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(model, name='bert', epoch=None):\n",
    "    global bert_tokenizer\n",
    "    global nltk_tokenizer\n",
    "    global instance_converter\n",
    "    result_file_name='ranking.txt'\n",
    "    query_pass = read_passages(result_file_name)\n",
    "    queries = pd.read_csv(\"test.csv\", delimiter=\",\")\n",
    "    \n",
    "    if epoch is not None:\n",
    "        name += '_{}'.format(epoch)\n",
    "    with open('fact_checks/' + name + '_entity.tab', 'w', encoding='utf8') as output:\n",
    "            for qid in range(1, len(queries) + 1):\n",
    "                passage_id = queries['qid'].values[qid-1]\n",
    "                try:\n",
    "                    print('Query:', str(qid)+'/'+str(len(queries)))\n",
    "                    temp_relations, sources, targets, query_text = get_query(queries, qid)\n",
    "                    relations = []\n",
    "                    for rl in temp_relations:\n",
    "                        temp_rl = rl\n",
    "                        for ci in instance_converter:\n",
    "                            if ci in rl:\n",
    "                                temp_rl = temp_rl.replace(ci, instance_converter[ci])\n",
    "                        relations.append(temp_rl)\n",
    "                    \n",
    "                    rerank = rank_passages(bert_tokenizer, nltk_tokenizer, model, query_pass[passage_id], relations, sources, targets, query_text)\n",
    "                    for passage in rerank:\n",
    "                        print(str(passage_id) + '\\t' + passage.entity + '\\t' + passage.text + '\\t' + str(passage.score),\n",
    "                              file=output)\n",
    "                except FileNotFoundError as file_error:\n",
    "                    for i in range(len(query_pass[qid])):\n",
    "                        print(str(qid) + '\\t-\\t-\\t0', file=output)\n",
    "\n",
    "                    print(file_error)\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "accumulation_grad = 32\n",
    "min_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('size of training set {}'.format(len(training_set)))\n",
    "print('size of val set {}'.format(len(val_set)))\n",
    "\n",
    "for ep in range(0, epochs):\n",
    "    gc.collect()\n",
    "    print('epoch: {}'.format(ep+1))\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    cnt_step = 0\n",
    "    cnt_acc = 0\n",
    "    model.zero_grad()\n",
    "    for i, (in_1, seg_1, attn_1, in_2, seg_2, attn_2, in_3, seg_3, attn_3, y_3) in tqdm(enumerate(training_set)):\n",
    "        loss, logits = model(in_1, seg_1, attn_1, in_2, seg_2, attn_2, in_3, seg_3, attn_3, y_3.to(device))\n",
    "        train_loss += loss.item()\n",
    "        loss = loss / (accumulation_grad/batch_size)\n",
    "        loss.backward()\n",
    "        cnt_acc += batch_size\n",
    "\n",
    "        if cnt_acc % accumulation_grad == 0:\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "        cnt_step += 1\n",
    "    print('training loss {}'.format(train_loss/cnt_step))\n",
    "        \n",
    "    model.zero_grad()\n",
    "    model.eval()\n",
    "    cnt_step = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (in_1, seg_1, attn_1, in_2, seg_2, attn_2, in_3, seg_3, attn_3, y_3) in tqdm(enumerate(val_set)):\n",
    "            loss, logits = model(in_1, seg_1, attn_1, in_2, seg_2, attn_2, in_3, seg_3, attn_3, y_3.to(device))\n",
    "            val_loss += loss.item()\n",
    "            cnt_step += 1\n",
    "        print('val loss {}'.format(val_loss/cnt_step))\n",
    "    \n",
    "    val_loss = val_loss/cnt_step\n",
    "    if min_loss > val_loss:\n",
    "        print('We have a new val loss')\n",
    "        min_loss = val_loss\n",
    "        torch.save(model, 'models/bert_entity_sentences/bert_entity.pth')\n",
    "        with open('models/bert_entity_sentences/bert_tokenizer_entity.pickle', 'wb') as handle:\n",
    "            pickle.dump(bert_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del optimizer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del loss\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL FINETUNE\n",
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "last_hidden_layer.weight\n",
      "last_hidden_layer.bias\n",
      "last_hidden_layer_1.weight\n",
      "last_hidden_layer_1.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "best_model = torch.load('models/bert_entity_sentences/bert_entity.pth', map_location=device)\n",
    "best_tokenizer = pickle.load(open(\"models/bert_entity_sentences/bert_tokenizer_entity.pickle\",\"rb\"))\n",
    "best_model.to(device)\n",
    "\n",
    "bert_tokenizer = best_tokenizer\n",
    "\n",
    "\n",
    "# write_results(best_model)\n",
    "\n",
    "FULL_FINETUNE = True\n",
    "\n",
    "optimizer_grouped_parameters = None\n",
    "param_optimizer = list(best_model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "\n",
    "if FULL_FINETUNE:\n",
    "    print('ALL FINETUNE')\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    print('NO ALL FINETUNE')\n",
    "    #         {'params': model.last_hidden_layer.parameters(),\n",
    "#          'weight_decay_rate': 0.01},\n",
    "\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': best_model.classifier.parameters(),\n",
    "         'weight_decay_rate': 0.01}\n",
    "    ]\n",
    "\n",
    "for n, p in param_optimizer:\n",
    "    print(n)\n",
    "\n",
    "meta_learning_optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pairs(bert_tokenizer, model, passages, relations, sources, targets, query_text):\n",
    "        \n",
    "    pair_passages = []\n",
    "    for p1, p2 in it.combinations(passages, 2):\n",
    "        if p1.text != p2.text:\n",
    "            pair_passages.append([p1.text, int(p1.score), p2.text, int(p2.score)])\n",
    "            \n",
    "    pair_passages = np.asarray(pair_passages)\n",
    "    \n",
    "    all_first_pair = []\n",
    "    all_second_pair = []\n",
    "    \n",
    "    for relation, source, target in zip(relations, sources, targets):\n",
    "                \n",
    "        relation = [relation] * len(pair_passages)\n",
    "        source = [source] * len(pair_passages)\n",
    "        target = [target] * len(pair_passages)\n",
    "        \n",
    "        \n",
    "        x_fp_1, x_fp_1_tokens, segment_id_fp_1, attention_mask_fp_1,\\\n",
    "        x_fp_2, x_fp_2_tokens, segment_id_fp_2, attention_mask_fp_2,\\\n",
    "        x_fp_3, x_fp_3_tokens, segment_id_fp_3, attention_mask_fp_3 = transform_data_x_sentences(bert_tokenizer,\\\n",
    "                                                                                                         pair_passages[:, 0], relation, source, target)\n",
    "        \n",
    "        x_sp_1, x_sp_1_tokens, segment_id_sp_1, attention_mask_sp_1,\\\n",
    "        x_sp_2, x_sp_2_tokens, segment_id_sp_2, attention_mask_sp_2,\\\n",
    "        x_sp_3, x_sp_3_tokens, segment_id_sp_3, attention_mask_sp_3 = transform_data_x_sentences(bert_tokenizer,\\\n",
    "                                                                                                         pair_passages[:, 2], relation, source, target)\n",
    "\n",
    "\n",
    "        \n",
    "        x_fp_1_tokens_tensor, segment_id_fp_1_tensor, attention_mask_fp_1_tensor = convert_to_tensor_x(x_fp_1_tokens,\\\n",
    "                                                                                                             segment_id_fp_1, attention_mask_fp_1)\n",
    "        x_fp_2_tokens_tensor, segment_id_fp_2_tensor, attention_mask_fp_2_tensor = convert_to_tensor_x(x_fp_2_tokens,\\\n",
    "                                                                                                             segment_id_fp_2, attention_mask_fp_2)\n",
    "        x_fp_3_tokens_tensor, segment_id_fp_3_tensor, attention_mask_fp_3_tensor = convert_to_tensor_x(x_fp_3_tokens,\\\n",
    "                                                                                                             segment_id_fp_3, attention_mask_fp_3) \n",
    "        \n",
    "        x_sp_1_tokens_tensor, segment_id_sp_1_tensor, attention_mask_sp_1_tensor = convert_to_tensor_x(x_sp_1_tokens,\\\n",
    "                                                                                                             segment_id_sp_1, attention_mask_sp_1)\n",
    "        x_sp_2_tokens_tensor, segment_id_sp_2_tensor, attention_mask_sp_2_tensor = convert_to_tensor_x(x_sp_2_tokens,\\\n",
    "                                                                                                             segment_id_sp_2, attention_mask_sp_2)\n",
    "        x_sp_3_tokens_tensor, segment_id_sp_3_tensor, attention_mask_sp_3_tensor = convert_to_tensor_x(x_sp_3_tokens,\\\n",
    "                                                                                                             segment_id_sp_3, attention_mask_sp_3) \n",
    "        \n",
    "        FIELDS = ('x', 'x_1_tokens_tensors', 'segment_id_1_tensors',\\\n",
    "                        'attention_mask_1_tensors', 'x_2_tokens_tensors', 'segment_id_2_tensors',\\\n",
    "                        'attention_mask_2_tensors', 'x_3_tokens_tensors', 'segment_id_3_tensors',\\\n",
    "                        'attention_mask_3_tensors', 'scores')\n",
    "        \n",
    "        Dataset = collections.namedtuple('Dataset', FIELDS)\n",
    "        \n",
    "        first_pair = Dataset(x=x_fp_1, x_1_tokens_tensors=x_fp_1_tokens_tensor, \n",
    "                             segment_id_1_tensors=segment_id_fp_1_tensor, \n",
    "                             attention_mask_1_tensors=attention_mask_fp_1_tensor,\n",
    "                             x_2_tokens_tensors=x_fp_2_tokens_tensor, \n",
    "                             segment_id_2_tensors=segment_id_fp_2_tensor, \n",
    "                             attention_mask_2_tensors=attention_mask_fp_2_tensor,\n",
    "                             x_3_tokens_tensors=x_fp_3_tokens_tensor, \n",
    "                             segment_id_3_tensors=segment_id_fp_3_tensor, \n",
    "                             attention_mask_3_tensors=attention_mask_fp_3_tensor,\n",
    "                             scores=pair_passages[:, 1])\n",
    "        \n",
    "        second_pair = Dataset(x=x_sp_1, x_1_tokens_tensors=x_sp_1_tokens_tensor, \n",
    "                             segment_id_1_tensors=segment_id_sp_1_tensor, \n",
    "                             attention_mask_1_tensors=attention_mask_sp_1_tensor,\n",
    "                             x_2_tokens_tensors=x_sp_2_tokens_tensor, \n",
    "                             segment_id_2_tensors=segment_id_sp_2_tensor, \n",
    "                             attention_mask_2_tensors=attention_mask_sp_2_tensor,\n",
    "                             x_3_tokens_tensors=x_sp_3_tokens_tensor, \n",
    "                             segment_id_3_tensors=segment_id_sp_3_tensor, \n",
    "                             attention_mask_3_tensors=attention_mask_sp_3_tensor,\n",
    "                             scores=pair_passages[:, 3])\n",
    "\n",
    "\n",
    "        all_first_pair.append(first_pair)\n",
    "        all_second_pair.append(second_pair)\n",
    "        \n",
    "    \n",
    "    return all_first_pair, all_second_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools as it\n",
    "\n",
    "# train_data = pd.read_csv('train.csv', delimiter=\",\")\n",
    "# val_data = pd.read_csv('val.csv', delimiter=\",\")\n",
    "# test_data = pd.read_csv('test.csv', delimiter=\",\")\n",
    "# all_queries = pd.read_csv('queries.csv', delimiter=\",\")\n",
    "# query_pass = read_passages('ranking.txt')\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# for _ in range(0, 1):\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for qid_train, qid_val in zip(train_data['qid'], val_data['qid']):\n",
    "#         print(qid_train, qid_val)\n",
    "#         new_parameters = list(best_model.parameters()).copy()\n",
    "        \n",
    "#         temp_relations_train, sources_train, targets_train, query_text_train = get_query(all_queries, \n",
    "#                                                                  int(qid_train))\n",
    "#         temp_relations_val, sources_val, targets_val, query_text_val = get_query(all_queries, \n",
    "#                                                                  int(qid_val))\n",
    "        \n",
    "#         passages = query_pass[int(qid_train)]\n",
    "#         all_train_first_pair, all_train_second_pair = transform_pairs(best_tokenizer, best_model, passages, temp_relations_train, \n",
    "#                                                           sources_train, targets_train, query_text_train)\n",
    "        \n",
    "#         inner_loss = None\n",
    "#         cnt_train = 0\n",
    "#         for _ in range(0, 10):\n",
    "#             for first_pair, second_pair in zip(all_train_first_pair, all_train_second_pair):\n",
    "\n",
    "#                 for idx in range(0, len(first_pair.x)):\n",
    "#                     pred_fp = best_model(first_pair.x_1_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "#                         first_pair.attention_mask_1_tensors[idx].unsqueeze(0), first_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "#                         first_pair.segment_id_2_tensors[idx].unsqueeze(0), first_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "#                         first_pair.x_3_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "#                         first_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "#                     pred_sp = best_model(second_pair.x_1_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "#                         second_pair.attention_mask_1_tensors[idx].unsqueeze(0), second_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "#                         second_pair.segment_id_2_tensors[idx].unsqueeze(0), second_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "#                         second_pair.x_3_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "#                         second_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "#                     if first_pair.scores[idx] > second_pair.scores[idx]:\n",
    "#                         S_ij = 1\n",
    "#                     elif first_pair.scores[idx] == second_pair.scores[idx]:\n",
    "#                         S_ij = 0\n",
    "#                     else:\n",
    "#                         S_ij = -1 \n",
    "\n",
    "# #                     if inner_loss is None:\n",
    "# #                         inner_loss = pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "# #                     else:\n",
    "# #                         inner_loss += pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "                    \n",
    "#                     inner_loss = pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "                    \n",
    "#                     cnt_train += 1\n",
    "               \n",
    "#                 grads = torch.autograd.grad(inner_loss, list(best_model.parameters()),create_graph=True)\n",
    "#                 new_parameters = [(new_parameters[i] - 1e-4 * grads[i]) for i in range(0, len(grads))]\n",
    "                \n",
    "#                 del grads\n",
    "#                 torch.cuda.empty_cache()\n",
    "        \n",
    "# #         print(\"task inner loss\", inner_loss.item()/cnt_train)\n",
    "        \n",
    "#         state_dict = best_model.state_dict()\n",
    "#         for n_p, i in zip(new_parameters, state_dict):\n",
    "#             state_dict[i] = n_p\n",
    "#         best_model.load_state_dict(state_dict)\n",
    "        \n",
    "#         del new_parameters\n",
    "#         torch.cuda.empty_cache()\n",
    "#         all_val_first_pair, all_val_second_pair = transform_pairs(best_tokenizer, best_model, passages, temp_relations_val, \n",
    "#                                                           sources_val, targets_val, query_text_val)\n",
    "        \n",
    "#         outer_loss = None\n",
    "#         task_val_loss = 0\n",
    "#         cnt_val = 0\n",
    "        \n",
    "#         for first_pair, second_pair in zip(all_val_first_pair, all_val_second_pair):\n",
    "            \n",
    "#             for idx in range(0, len(first_pair.x)):\n",
    "#                 pred_fp = best_model(first_pair.x_1_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "#                     first_pair.attention_mask_1_tensors[idx].unsqueeze(0), first_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "#                     first_pair.segment_id_2_tensors[idx].unsqueeze(0), first_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "#                     first_pair.x_3_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "#                     first_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "#                 pred_sp = best_model(second_pair.x_1_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "#                     second_pair.attention_mask_1_tensors[idx].unsqueeze(0), second_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "#                     second_pair.segment_id_2_tensors[idx].unsqueeze(0), second_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "#                     second_pair.x_3_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "#                     second_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "                \n",
    "#                 if first_pair.scores[idx] > second_pair.scores[idx]:\n",
    "#                     S_ij = 1\n",
    "#                 elif first_pair.scores[idx] == second_pair.scores[idx]:\n",
    "#                     S_ij = 0\n",
    "#                 else:\n",
    "#                     S_ij = -1 \n",
    "                \n",
    "#                 outer_loss = pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "#                 task_val_loss += outer_loss.item()\n",
    "#                 outer_loss.backward()\n",
    "#                 meta_learning_optimizer.step()\n",
    "#                 meta_learning_optimizer.zero_grad()\n",
    "#                 cnt_val += 1\n",
    "                \n",
    "#         print(\"task inner loss\", outer_loss / cnt_val)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools as it\n",
    "\n",
    "# train_data = pd.read_csv('train.csv', delimiter=\",\")\n",
    "# val_data = pd.read_csv('val.csv', delimiter=\",\")\n",
    "# test_data = pd.read_csv('test.csv', delimiter=\",\")\n",
    "# all_queries = pd.read_csv('queries.csv', delimiter=\",\")\n",
    "# query_pass = read_passages('ranking.txt')\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# for _ in range(0, 5):\n",
    "    \n",
    "    \n",
    "#     num_task = 0\n",
    "#     first_task = False\n",
    "#     sum_gradients = []\n",
    "#     for qid_train, qid_val in zip(train_data['qid'], val_data['qid']):\n",
    "#         print(qid_train, qid_val)\n",
    "#         fast_model = deepcopy(best_model)\n",
    "#         fast_model.to(device)\n",
    "#         inner_optimizer = AdamW(fast_model.parameters(), lr=2e-5)\n",
    "#         temp_relations_train, sources_train, targets_train, query_text_train = get_query(all_queries, \n",
    "#                                                                  int(qid_train))\n",
    "#         temp_relations_val, sources_val, targets_val, query_text_val = get_query(all_queries, \n",
    "#                                                                  int(qid_val))\n",
    "        \n",
    "#         passages = query_pass[int(qid_train)]\n",
    "#         all_train_first_pair, all_train_second_pair = transform_pairs(best_tokenizer, best_model, passages, temp_relations_train, \n",
    "#                                                           sources_train, targets_train, query_text_train)\n",
    "                                                                                                  \n",
    "        \n",
    "#         fast_model.train()\n",
    "#         inner_loss = None\n",
    "#         for _ in range(0, 15):\n",
    "            \n",
    "#             cnt_train_break = 0\n",
    "#             cnt_train = 1\n",
    "#             train_loss = 0\n",
    "#             accumulation_batch = 32\n",
    "#             for first_pair, second_pair in zip(all_train_first_pair, all_train_second_pair):\n",
    "\n",
    "#                 for idx in range(0, len(first_pair.x)):\n",
    "#                     pred_fp = fast_model(first_pair.x_1_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "#                         first_pair.attention_mask_1_tensors[idx].unsqueeze(0), first_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "#                         first_pair.segment_id_2_tensors[idx].unsqueeze(0), first_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "#                         first_pair.x_3_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "#                         first_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "#                     pred_sp = fast_model(second_pair.x_1_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "#                         second_pair.attention_mask_1_tensors[idx].unsqueeze(0), second_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "#                         second_pair.segment_id_2_tensors[idx].unsqueeze(0), second_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "#                         second_pair.x_3_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "#                         second_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "#                     if first_pair.scores[idx] > second_pair.scores[idx]:\n",
    "#                         S_ij = 1\n",
    "#                     elif first_pair.scores[idx] == second_pair.scores[idx]:\n",
    "#                         S_ij = 0\n",
    "#                     else:\n",
    "#                         S_ij = -1 \n",
    "\n",
    "#                     inner_loss = pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "#                     train_loss += inner_loss.item()\n",
    "#                     inner_loss = inner_loss / accumulation_batch\n",
    "# #                     print(pred_fp[0][0][0], pred_sp[0][0][0])\n",
    "                    \n",
    "#                     inner_loss.backward()\n",
    "#                     if cnt_train % accumulation_batch == 0:\n",
    "# #                         print(cnt_train)\n",
    "#                         inner_optimizer.step()\n",
    "#                         fast_model.zero_grad()\n",
    "                    \n",
    "#                     if cnt_train_break == 128:\n",
    "#                         break\n",
    "#                     cnt_train_break += 1\n",
    "#                     cnt_train += 1\n",
    "#             print(train_loss/(cnt_train-1)) \n",
    "#         del inner_loss\n",
    "#         torch.cuda.empty_cache()\n",
    "#         print(\"finish Task\")\n",
    "                \n",
    "#         all_val_first_pair, all_val_second_pair = transform_pairs(best_tokenizer, best_model, passages, temp_relations_val, \n",
    "#                                                           sources_val, targets_val, query_text_val)\n",
    "        \n",
    "#         q_loss = None\n",
    "#         saved_loss = None\n",
    "#         cnt_val = 0\n",
    "#         val_loss = 0\n",
    "#         cnt_break_val = 0\n",
    "#         for first_pair, second_pair in zip(all_val_first_pair, all_val_second_pair):\n",
    "            \n",
    "#             for idx in range(0, len(first_pair.x)):\n",
    "#                 pred_fp = fast_model(first_pair.x_1_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "#                     first_pair.attention_mask_1_tensors[idx].unsqueeze(0), first_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "#                     first_pair.segment_id_2_tensors[idx].unsqueeze(0), first_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "#                     first_pair.x_3_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "#                     first_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "#                 pred_sp = fast_model(second_pair.x_1_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "#                     second_pair.attention_mask_1_tensors[idx].unsqueeze(0), second_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "#                     second_pair.segment_id_2_tensors[idx].unsqueeze(0), second_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "#                     second_pair.x_3_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "#                     second_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "                \n",
    "#                 if first_pair.scores[idx] > second_pair.scores[idx]:\n",
    "#                     S_ij = 1\n",
    "#                 elif first_pair.scores[idx] == second_pair.scores[idx]:\n",
    "#                     S_ij = 0\n",
    "#                 else:\n",
    "#                     S_ij = -1 \n",
    "                \n",
    "#                 q_loss = pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "#                 q_loss = q_loss / len(all_val_first_pair)\n",
    "#                 val_loss += q_loss.item()\n",
    "#                 q_loss.backward()\n",
    "# #                 if cnt_val == 0:\n",
    "# #                     saved_loss = q_loss.clone()\n",
    "# #                 else:\n",
    "# #                     saved_loss += q_loss.clone()\n",
    "                \n",
    "# #                 fast_model.zero_grad()\n",
    "#                 if cnt_break_val == 128:\n",
    "#                     break\n",
    "#                 cnt_val += 1  \n",
    "#                 cnt_break_val+=1\n",
    "#             print(val_loss/cnt_val)\n",
    "                \n",
    "# #         saved_loss /= cnt_val\n",
    "        \n",
    "# #         saved_loss.backward()\n",
    "        \n",
    "#         fast_model.to(torch.device('cpu'))\n",
    "#         for i, params in enumerate(fast_model.parameters()):\n",
    "#             if first_task == False:\n",
    "#                 sum_gradients.append(deepcopy(params.grad))\n",
    "#             else:\n",
    "#                 sum_gradients[i] += deepcopy(params.grad)\n",
    "                        \n",
    "#         del fast_model, inner_optimizer, saved_loss\n",
    "#         torch.cuda.empty_cache()\n",
    "#         first_task = True\n",
    "#         num_task += 1\n",
    "# #         print(sum_gradients)\n",
    "        \n",
    "#     for i in range(0, len(sum_gradients)):\n",
    "#         print(\"before\")\n",
    "#         print(sum_gradients[i])\n",
    "#         print(\"after\")\n",
    "#         print(sum_gradients[i] / float(num_task))\n",
    "#         sum_gradients[i] = sum_gradients[i] / float(num_task)\n",
    "#     print(\"average\")\n",
    "#     print(sum_gradients)\n",
    "#     state_dict = best_model.state_dict()\n",
    "#     for n_p, i in zip(sum_gradients, state_dict):\n",
    "#         state_dict[i] = n_p\n",
    "#     best_model.load_state_dict(state_dict)\n",
    "        \n",
    "#     meta_learning_optimizer.step()\n",
    "#     best_model.zero_grad()\n",
    "        \n",
    "#     del sum_gradients\n",
    "#     gc.collect()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "train_data = pd.read_csv('train.csv', delimiter=\",\")\n",
    "val_data = pd.read_csv('val.csv', delimiter=\",\")\n",
    "test_data = pd.read_csv('test.csv', delimiter=\",\")\n",
    "all_queries = pd.read_csv('queries.csv', delimiter=\",\")\n",
    "query_pass = read_passages('ranking.txt')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "innerstepsize = 0.001\n",
    "outerstepsize0 = 0.1\n",
    "outeriterations = 5\n",
    "inneriterations = 30\n",
    "\n",
    "for iteration in range(0, outeriterations):\n",
    "\n",
    "    weights_before = deepcopy(best_model.state_dict())\n",
    "    \n",
    "    for qid_train, qid_val in zip(train_data['qid'], val_data['qid']):\n",
    "        print(qid_train, qid_val)\n",
    "        \n",
    "        best_model.to(device)\n",
    "\n",
    "        temp_relations_train, sources_train, targets_train, query_text_train = get_query(all_queries, \n",
    "                                                                 int(qid_train))\n",
    "        temp_relations_val, sources_val, targets_val, query_text_val = get_query(all_queries, \n",
    "                                                                 int(qid_val))\n",
    "        \n",
    "        passages = query_pass[int(qid_train)]\n",
    "        all_train_first_pair, all_train_second_pair = transform_pairs(best_tokenizer, best_model, passages, temp_relations_train, \n",
    "                                                          sources_train, targets_train, query_text_train)\n",
    "                                                                                                  \n",
    "        \n",
    "        best_model.train()\n",
    "        inner_loss = None\n",
    "        for _ in range(0, inneriterations):\n",
    "            cnt_train = 1\n",
    "            train_loss = 0\n",
    "\n",
    "            for first_pair, second_pair in zip(random.sample(all_train_first_pair, len(all_train_first_pair))[:100], \n",
    "                                               random.sample(all_train_second_pair, len(all_train_second_pair))[:100]:\n",
    "\n",
    "                for idx in range(0, len(first_pair.x)):\n",
    "                    pred_fp = best_model(first_pair.x_1_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "                        first_pair.attention_mask_1_tensors[idx].unsqueeze(0), first_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "                        first_pair.segment_id_2_tensors[idx].unsqueeze(0), first_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "                        first_pair.x_3_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "                        first_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "                    pred_sp = best_model(second_pair.x_1_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "                        second_pair.attention_mask_1_tensors[idx].unsqueeze(0), second_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "                        second_pair.segment_id_2_tensors[idx].unsqueeze(0), second_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "                        second_pair.x_3_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "                        second_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "                    if first_pair.scores[idx] > second_pair.scores[idx]:\n",
    "                        S_ij = 1\n",
    "                    elif first_pair.scores[idx] == second_pair.scores[idx]:\n",
    "                        S_ij = 0\n",
    "                    else:\n",
    "                        S_ij = -1 \n",
    "\n",
    "                    inner_loss = pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "                    inner_loss.backward()\n",
    "                    train_loss += inner_loss.item()              \n",
    "                    for param in model.parameters():\n",
    "                        param.data -= innerstepsize * param.grad.data\n",
    "                                               \n",
    "                    cnt_train += 1\n",
    "            print(train_loss/(cnt_train-1)) \n",
    "        del inner_loss\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"finish Task\")\n",
    "                \n",
    "        all_val_first_pair, all_val_second_pair = transform_pairs(best_tokenizer, best_model, passages, temp_relations_val, \n",
    "                                                          sources_val, targets_val, query_text_val)\n",
    "        best_model.eval()\n",
    "        q_loss = None\n",
    "        cnt_val = 0\n",
    "        val_loss = 0\n",
    "\n",
    "    for first_pair, second_pair in zip(all_val_first_pair, all_val_second_pair):\n",
    "            \n",
    "            for idx in range(0, len(first_pair.x)):\n",
    "                pred_fp = best_model(first_pair.x_1_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "                    first_pair.attention_mask_1_tensors[idx].unsqueeze(0), first_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "                    first_pair.segment_id_2_tensors[idx].unsqueeze(0), first_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "                    first_pair.x_3_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "                    first_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "                pred_sp = best_model(second_pair.x_1_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "                    second_pair.attention_mask_1_tensors[idx].unsqueeze(0), second_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "                    second_pair.segment_id_2_tensors[idx].unsqueeze(0), second_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "                    second_pair.x_3_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "                    second_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "                \n",
    "                if first_pair.scores[idx] > second_pair.scores[idx]:\n",
    "                    S_ij = 1\n",
    "                elif first_pair.scores[idx] == second_pair.scores[idx]:\n",
    "                    S_ij = 0\n",
    "                else:\n",
    "                    S_ij = -1 \n",
    "                \n",
    "                q_loss = pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "                q_loss = q_loss / len(all_val_first_pair)\n",
    "                val_loss += q_loss.item()\n",
    "                cnt_val += 1  \n",
    "            print(val_loss/cnt_val)\n",
    "                \n",
    "    weights_after = best_model.state_dict()\n",
    "    outerstepsize = outerstepsize0 * (1 - iteration / outeriterations) # linear schedule\n",
    "    model.load_state_dict({name : \n",
    "        weights_before[name] + (weights_after[name] - weights_before[name]) * outerstepsize \n",
    "        for name in weights_before})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 35\n",
      "0.39797250899723063\n",
      "0.317992667451425\n",
      "0.2893703974382437\n",
      "0.27733493439759577\n",
      "0.2756504666556747\n",
      "0.2736845723597901\n",
      "0.26966798097430317\n",
      "0.26641213700918065\n",
      "0.2693179442569458\n",
      "0.2665028119471031\n",
      "0.26352726032440377\n",
      "0.26387225234527\n",
      "0.26329002965100967\n",
      "0.26157419045603125\n",
      "0.261898591185175\n",
      "0.26102411341165227\n",
      "0.26125291696036873\n",
      "0.26138552641012197\n",
      "0.26070264050762937\n",
      "0.2609200755729765\n",
      "0.2608264530280049\n",
      "0.26054572840347034\n",
      "0.2609022171633256\n",
      "0.2608351590769914\n",
      "0.2611195031548921\n",
      "0.26115372676691867\n",
      "0.2622838529022952\n",
      "0.2608546538225485\n",
      "0.2602459659710466\n",
      "0.260033931102619\n",
      "finish Task\n",
      "0.2808420009190502\n",
      "4 17\n",
      "0.5403952299657326\n",
      "0.4412925555491828\n",
      "0.42837414997879425\n",
      "0.4190454647013082\n",
      "0.40320568254875705\n",
      "0.3826213339486581\n",
      "0.36114917239022026\n",
      "0.3533344291250709\n",
      "0.34745146695242396\n",
      "0.34466432095622157\n",
      "0.3431849891514095\n",
      "0.3420814105440191\n",
      "0.3420093847159229\n",
      "0.341162464360453\n",
      "0.3410142666816078\n",
      "0.3404131688248813\n",
      "0.34055871445946573\n",
      "0.3404209507775948\n",
      "0.3402904494562434\n",
      "0.3402202447458072\n",
      "0.3399104245812996\n",
      "0.33986827909928463\n",
      "0.3402220645594494\n",
      "0.3397852529721045\n",
      "0.33974980267988536\n",
      "0.3395973643288475\n",
      "0.3395246593023665\n",
      "0.3392396333017976\n",
      "0.33944625519771726\n",
      "0.3393755465279623\n",
      "finish Task\n",
      "0.3621177183921636\n",
      "14 19\n",
      "0.5091797162469411\n",
      "0.4377285739212614\n",
      "0.4023986415725511\n",
      "0.38576086066883564\n",
      "0.3813549967990323\n",
      "0.3790268479972765\n",
      "0.3775748940123942\n",
      "0.37535556427380473\n",
      "0.3758105919276962\n",
      "0.3761339514785946\n",
      "0.37535662644033235\n",
      "0.37494433537948896\n",
      "0.3748792332642228\n",
      "0.37419117318770145\n",
      "0.37409825565953053\n",
      "0.376297561480269\n",
      "0.37650958913309546\n",
      "0.37557670384946223\n",
      "0.3745406531363906\n",
      "0.37473452815150404\n",
      "0.3738193748144761\n",
      "0.3751349616789503\n",
      "0.3732506241899022\n",
      "0.3733931687276954\n",
      "0.3732402871816936\n",
      "0.3731825375730696\n",
      "0.37366956560710174\n",
      "0.3736592630613817\n",
      "0.3740098657074175\n",
      "0.3738204618018435\n",
      "finish Task\n",
      "0.47747492943941494\n",
      "5 22\n",
      "0.6202887841474649\n",
      "0.4887204438115628\n",
      "0.46132102493091565\n",
      "0.4498042165781776\n",
      "0.4493352418312262\n",
      "0.44883817557923217\n",
      "0.447264969606991\n",
      "0.4510354877324613\n",
      "0.4498215994052068\n",
      "0.4465773034307381\n",
      "0.4460543563377202\n",
      "0.4451034366144775\n",
      "0.4450726145204384\n",
      "0.4451609456929231\n",
      "0.4451362784401386\n",
      "0.44524076052974265\n",
      "0.44534992897322817\n",
      "0.4450026395788024\n",
      "0.44492083412640643\n",
      "0.4452375310064168\n",
      "0.44479843425562876\n",
      "0.4446075640471449\n",
      "0.4446204950900916\n",
      "0.44488436173297036\n",
      "0.4445589336905377\n",
      "0.4445735585872271\n",
      "0.4447510567739768\n",
      "0.44445710681754536\n",
      "0.4449693824390761\n",
      "0.444630253991786\n",
      "finish Task\n",
      "0.5109515918272268\n",
      "15 36\n",
      "0.5409311255371209\n",
      "0.39282585345660515\n",
      "0.3836764044847266\n",
      "0.34612893845042353\n",
      "0.3292715965468834\n",
      "0.3255330615484285\n",
      "0.31431493117800063\n",
      "0.31254690295373877\n",
      "0.31054786253499134\n",
      "0.3105804006309545\n",
      "0.30914763853862376\n",
      "0.30889149614213507\n",
      "0.30829184768758816\n",
      "0.3079928809402423\n",
      "0.3078451725080297\n",
      "0.3078488167579811\n",
      "0.3077598806894313\n",
      "0.30782832512833114\n",
      "0.3075845779128589\n",
      "0.3075656578504522\n",
      "0.3074668077908457\n",
      "0.3074336038958698\n",
      "0.30723200022376973\n",
      "0.3073057492180711\n",
      "0.3071550593867245\n",
      "0.3071060539004337\n",
      "0.3073657600214558\n",
      "0.30723315954886016\n",
      "0.30727398301400133\n",
      "0.30698621470679605\n",
      "finish Task\n",
      "0.3933327069969878\n",
      "25 49\n",
      "0.6085715960528013\n",
      "0.45766697435663944\n",
      "0.3993416451388174\n",
      "0.39549754027721173\n",
      "0.3972607533162957\n",
      "0.3830996824766887\n",
      "0.37939098796819554\n",
      "0.37844523786872986\n",
      "0.3740159355686388\n",
      "0.3721196856680616\n",
      "0.3714214439257707\n",
      "0.3712371042626279\n",
      "0.37109617318031923\n",
      "0.37095808875188874\n",
      "0.3702288585749456\n",
      "0.37007930452565946\n",
      "0.37024597105778795\n",
      "0.37014090842410097\n",
      "0.36989910588095043\n",
      "0.3701428220707461\n",
      "0.36944813256646364\n",
      "0.3697802858165248\n",
      "0.3696062790830828\n",
      "0.3689235298976403\n",
      "0.3689490278015447\n",
      "0.368940776185543\n",
      "0.36886549538779656\n",
      "0.36868386609420023\n",
      "0.3687184510201764\n",
      "0.36872486531078713\n",
      "finish Task\n",
      "0.15969081888499656\n",
      "0.16059190400650192\n",
      "0.16536340032785793\n",
      "31 32\n",
      "0.5642572908722033\n",
      "0.516222966197555\n",
      "0.4615724607098157\n",
      "0.41421614833741704\n",
      "0.39328056766796504\n",
      "0.3810822476045661\n",
      "0.37349420039504877\n",
      "0.36909473079900523\n",
      "0.3560640232280513\n",
      "0.3503070878986335\n",
      "0.3494993921402448\n",
      "0.3475978324879318\n",
      "0.35269288707905816\n",
      "0.3721681489922929\n",
      "0.35875409388752677\n",
      "0.34182256822863677\n",
      "0.3388788945271393\n",
      "0.3374600602424027\n",
      "0.33712520721818623\n",
      "0.33703817339610315\n",
      "0.3383602874207911\n",
      "0.3370988358346052\n",
      "0.33756093708758483\n",
      "0.3360578302419665\n",
      "0.3361137779799715\n",
      "0.3363044704733939\n",
      "0.33631992391544896\n",
      "0.3359326880600001\n",
      "0.33654296417333196\n",
      "0.33582532862600695\n",
      "finish Task\n",
      "0.3514160527943877\n",
      "3 20\n",
      "0.522488090265599\n",
      "0.42282333819684426\n",
      "0.3725064044494344\n",
      "0.3552647148323579\n",
      "0.34509131638072893\n",
      "0.33890788994023796\n",
      "0.3353501064678766\n",
      "0.3284005437696094\n",
      "0.32364032412435684\n",
      "0.32297504369359764\n",
      "0.33377731695058865\n",
      "0.324617640908849\n",
      "0.3240603270116597\n",
      "0.3227656100508463\n",
      "0.3284266883506648\n",
      "0.32397241381053765\n",
      "0.3289546234078496\n",
      "0.32127447414983695\n",
      "0.31904503073636464\n",
      "0.32108369088668376\n",
      "0.3209670040951017\n",
      "0.31842131203951074\n",
      "0.31924736232831946\n",
      "0.3217300139301178\n",
      "0.3192993842790008\n",
      "0.32152904554716527\n",
      "0.32225931273609054\n",
      "0.31834777016567467\n",
      "0.3190856326806121\n",
      "0.31961225675929705\n",
      "finish Task\n",
      "0.4115141873248494\n",
      "12 27\n",
      "0.5435937004551913\n",
      "0.3701626525102657\n",
      "0.3271829695704243\n",
      "0.2970927858202308\n",
      "0.27868644927861336\n",
      "0.260804174910875\n",
      "0.2564728956539629\n",
      "0.2542935856190959\n",
      "0.26259186468009854\n",
      "0.25574892118047243\n",
      "0.2547990878617728\n",
      "0.24970718262023614\n",
      "0.25493978940432377\n",
      "0.2521301530810554\n",
      "0.258962891246347\n",
      "0.24936258063014557\n",
      "0.2524079715669238\n",
      "0.25040527597196466\n",
      "0.2542624649179165\n",
      "0.252052373466166\n",
      "0.2536611023602229\n",
      "0.24871137609109553\n",
      "0.2515326534302172\n",
      "0.2485784548962172\n",
      "0.2524591153363489\n",
      "0.24929907777056046\n",
      "0.2518602887214636\n",
      "0.24828224188290385\n",
      "0.25114252323815006\n",
      "0.24911181829572862\n",
      "finish Task\n",
      "0.3748927196105789\n",
      "18 34\n",
      "0.49648895759125417\n",
      "0.35331073213612435\n",
      "0.3156600419960629\n",
      "0.302735452746263\n",
      "0.2940470456639648\n",
      "0.2886671605618484\n",
      "0.285975627871761\n",
      "0.2812219090810595\n",
      "0.2801935649562318\n",
      "0.2771658071312285\n",
      "0.27590730128579716\n",
      "0.27424721167634425\n",
      "0.2727337907052032\n",
      "0.27233683310161527\n",
      "0.2713374229299303\n",
      "0.27140540569804744\n",
      "0.2715636239079891\n",
      "0.27100578202977965\n",
      "0.27071706103793347\n",
      "0.26975230639516573\n",
      "0.2699187544859282\n",
      "0.269786352617661\n",
      "0.2700538180743503\n",
      "0.2690191884886409\n",
      "0.26921966354228255\n",
      "0.2687300530639541\n",
      "0.2691514808792986\n",
      "0.2689764904590256\n",
      "0.26915344567740784\n",
      "0.269555028464508\n",
      "finish Task\n",
      "0.476284276065508\n",
      "9 26\n",
      "0.6489347804691804\n",
      "0.47295895688936274\n",
      "0.4338451536807984\n",
      "0.4344727003770344\n",
      "0.4150502350357481\n",
      "0.40266431984777185\n",
      "0.3953828595332515\n",
      "0.3901196785482226\n",
      "0.3904588616811934\n",
      "0.3865136911652484\n",
      "0.3885442831868322\n",
      "0.38511627214868194\n",
      "0.38511560169172576\n",
      "0.3830460579850505\n",
      "0.38317777420253496\n",
      "0.38269129617286746\n",
      "0.3829125794344717\n",
      "0.38284151745433304\n",
      "0.38235253132734587\n",
      "0.3820789497971842\n",
      "0.3812489379336558\n",
      "0.3818757621065547\n",
      "0.3808260617818632\n",
      "0.3837245090213339\n",
      "0.3895265627627422\n",
      "0.3839988509163557\n",
      "0.3863078915843102\n",
      "0.44112306429034787\n",
      "0.4388311252983463\n",
      "0.413377751474027\n",
      "finish Task\n",
      "0.4530696541682133\n",
      "8 10\n",
      "0.4997359574713114\n",
      "0.4250597313566299\n",
      "0.4113212970472436\n",
      "0.39925461211581986\n",
      "0.3922767648541817\n",
      "0.3902940142053074\n",
      "0.3880349347053756\n",
      "0.3878296873755907\n",
      "0.38551224028725145\n",
      "0.38396756710089913\n",
      "0.38374623021235593\n",
      "0.38329328992600376\n",
      "0.3840139713852566\n",
      "0.3831717632837512\n",
      "0.3827392013731237\n",
      "0.3830913419062065\n",
      "0.3842543328915285\n",
      "0.3831105789729906\n",
      "0.3827181968441308\n",
      "0.3826367878033684\n",
      "0.3823612631199344\n",
      "0.3821875551554877\n",
      "0.3821542288221386\n",
      "0.3823719707067371\n",
      "0.38180341469766715\n",
      "0.38194899395674653\n",
      "0.38188384502819317\n",
      "0.3822762038682192\n",
      "0.3822987370012676\n",
      "0.38227762902588713\n",
      "finish Task\n",
      "0.1913413763291449\n",
      "0.19134868384218323\n",
      "6 24\n",
      "0.49838391596065257\n",
      "0.38528584444056246\n",
      "0.35734473712013126\n",
      "0.35531885182146994\n",
      "0.3477698470265591\n",
      "0.3526414928884661\n",
      "0.34995977569130204\n",
      "0.3545073264989634\n",
      "0.34192333391656043\n",
      "0.3407029381535516\n",
      "0.34032904858510704\n",
      "0.3398849362679367\n",
      "0.3407504184436203\n",
      "0.3421281099862913\n",
      "0.34613839123220147\n",
      "0.3491331903136536\n",
      "0.3404183618254057\n",
      "0.3392622375716\n",
      "0.33915908255446436\n",
      "0.3390085272032563\n",
      "0.33894854940655933\n",
      "0.3390049214416077\n",
      "0.3394366032252102\n",
      "0.341499889796123\n",
      "0.3407905958886682\n",
      "0.3406390006984979\n",
      "0.34243343609617344\n",
      "0.33944509855405486\n",
      "0.3388391387001592\n",
      "0.33934341287461156\n",
      "finish Task\n",
      "0.3612984694132289\n",
      "16 51\n",
      "0.6474295277384817\n",
      "0.4231442898583184\n",
      "0.3831770575184551\n",
      "0.3582139648621636\n",
      "0.3534795852149517\n",
      "0.35671272071313\n",
      "0.3513557980867749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34487649642600227\n",
      "0.34396091869842904\n",
      "0.34346668523928636\n",
      "0.34141022080306355\n",
      "0.34137597143619786\n",
      "0.33998742256599845\n",
      "0.33967044234414456\n",
      "0.33981445997268284\n",
      "0.33986681203940183\n",
      "0.3399660102108161\n",
      "0.3395300371381644\n",
      "0.339076728338718\n",
      "0.3379382892468584\n",
      "0.3376252383434045\n",
      "0.3372541933467863\n",
      "0.33743906290714837\n",
      "0.33750448426553115\n",
      "0.33746281018595786\n",
      "0.3372556753974538\n",
      "0.3372041034978506\n",
      "0.33721802302629894\n",
      "0.33699895345508735\n",
      "0.3371892194142705\n",
      "finish Task\n",
      "0.10276560084703058\n",
      "0.10291083489767407\n",
      "0.10290427388341462\n",
      "0.10288876700677722\n",
      "23 52\n",
      "0.6021922330602143\n",
      "0.4535989159735021\n",
      "0.4114043025833028\n",
      "0.40295925900486246\n",
      "0.3927554549764602\n",
      "0.39012703619322553\n",
      "0.38751759422646453\n",
      "0.3852653804708317\n",
      "0.3839091374805634\n",
      "0.38492786836433524\n",
      "0.38516787892517634\n",
      "0.3868706831833281\n",
      "0.3840655851410936\n",
      "0.38368945054158754\n",
      "0.3830241784390031\n",
      "0.38312633634843324\n",
      "0.3826247271566588\n",
      "0.38308476893603355\n",
      "0.38231094177112906\n",
      "0.382767178467065\n",
      "0.3821023689064345\n",
      "0.38323664808718694\n",
      "0.3825426167015467\n",
      "0.38284818717148306\n",
      "0.3822046252412481\n",
      "0.382640776186453\n",
      "0.382164961946552\n",
      "0.3824566408449089\n",
      "0.3817890375742318\n",
      "0.3823701501217173\n",
      "finish Task\n",
      "0.236613431117855\n",
      "0.23737760501843222\n",
      "37 38\n",
      "0.4442968211596372\n",
      "0.37077202375542806\n",
      "0.3450908826483798\n",
      "0.3417157592805248\n",
      "0.3415256870013409\n",
      "0.3356743161330701\n",
      "0.33122422145686914\n",
      "0.33135098409572505\n",
      "0.3305335912415363\n",
      "0.32877747842117594\n",
      "0.32844324126020524\n",
      "0.3291922065912154\n",
      "0.3353225962098025\n",
      "0.32976287430793055\n",
      "0.32829408338544785\n",
      "0.3277590207591573\n",
      "0.32823560249012956\n",
      "0.32777019381100064\n",
      "0.3286059755827634\n",
      "0.32795290601266475\n",
      "0.32867596269105737\n",
      "0.3278819455198998\n",
      "0.3284148421779908\n",
      "0.32791410311719615\n",
      "0.32849042872088147\n",
      "0.32758405700895593\n",
      "0.32766761919715404\n",
      "0.32722771332542927\n",
      "0.3273114374983131\n",
      "0.32714058964775\n",
      "finish Task\n",
      "0.6707494594198655\n",
      "7 35\n",
      "0.5102460327176236\n",
      "0.3294962073621004\n",
      "0.2866298666122539\n",
      "0.27795194166682846\n",
      "0.27468313540246064\n",
      "0.2699111542102239\n",
      "0.26928768055194857\n",
      "0.26816229607637354\n",
      "0.26518444477439046\n",
      "0.26430332783574656\n",
      "0.26378888433045206\n",
      "0.26329991908831807\n",
      "0.26258191893830574\n",
      "0.26232545487194014\n",
      "0.2614745742603703\n",
      "0.2613680380993376\n",
      "0.2623148607480051\n",
      "0.2610164739442864\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "\n",
    "train_data = pd.read_csv('train.csv', delimiter=\",\")\n",
    "val_data = pd.read_csv('val.csv', delimiter=\",\")\n",
    "test_data = pd.read_csv('test.csv', delimiter=\",\")\n",
    "all_queries = pd.read_csv('queries.csv', delimiter=\",\")\n",
    "query_pass = read_passages('ranking.txt')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for _ in range(0, 5):\n",
    "    \n",
    "    \n",
    "    num_task = 0\n",
    "    first_task = False\n",
    "    sum_gradients = []\n",
    "    for qid_train, qid_val in zip(train_data['qid'], val_data['qid']):\n",
    "        print(qid_train, qid_val)\n",
    "        best_model.to(device)\n",
    "        inner_optimizer = AdamW(best_model.parameters(), lr=2e-5)\n",
    "        temp_relations_train, sources_train, targets_train, query_text_train = get_query(all_queries, \n",
    "                                                                 int(qid_train))\n",
    "        temp_relations_val, sources_val, targets_val, query_text_val = get_query(all_queries, \n",
    "                                                                 int(qid_val))\n",
    "        \n",
    "        passages = query_pass[int(qid_train)]\n",
    "        all_train_first_pair, all_train_second_pair = transform_pairs(best_tokenizer, best_model, passages, temp_relations_train, \n",
    "                                                          sources_train, targets_train, query_text_train)\n",
    "                                                                                                  \n",
    "        \n",
    "        best_model.train()\n",
    "        inner_loss = None\n",
    "        for _ in range(0, 30):\n",
    "            \n",
    "            cnt_train_break = 0\n",
    "            cnt_train = 1\n",
    "            train_loss = 0\n",
    "            accumulation_batch = 32\n",
    "            for first_pair, second_pair in zip(all_train_first_pair, all_train_second_pair):\n",
    "\n",
    "                for idx in range(0, len(first_pair.x)):\n",
    "                    pred_fp = best_model(first_pair.x_1_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "                        first_pair.attention_mask_1_tensors[idx].unsqueeze(0), first_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "                        first_pair.segment_id_2_tensors[idx].unsqueeze(0), first_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "                        first_pair.x_3_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "                        first_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "                    pred_sp = best_model(second_pair.x_1_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "                        second_pair.attention_mask_1_tensors[idx].unsqueeze(0), second_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "                        second_pair.segment_id_2_tensors[idx].unsqueeze(0), second_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "                        second_pair.x_3_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "                        second_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "                    if first_pair.scores[idx] > second_pair.scores[idx]:\n",
    "                        S_ij = 1\n",
    "                    elif first_pair.scores[idx] == second_pair.scores[idx]:\n",
    "                        S_ij = 0\n",
    "                    else:\n",
    "                        S_ij = -1 \n",
    "\n",
    "                    inner_loss = pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "                    train_loss += inner_loss.item()\n",
    "                    inner_loss = inner_loss / accumulation_batch\n",
    "#                     print(pred_fp[0][0][0], pred_sp[0][0][0])\n",
    "                    \n",
    "                    inner_loss.backward()\n",
    "                    if cnt_train % accumulation_batch == 0:\n",
    "#                         print(cnt_train)\n",
    "                        inner_optimizer.step()\n",
    "                        best_model.zero_grad()\n",
    "                    \n",
    "#                     if cnt_train_break == 128:\n",
    "#                         break\n",
    "#                     cnt_train_break += 1\n",
    "                    cnt_train += 1\n",
    "            print(train_loss/(cnt_train-1)) \n",
    "        del inner_loss\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"finish Task\")\n",
    "                \n",
    "        all_val_first_pair, all_val_second_pair = transform_pairs(best_tokenizer, best_model, passages, temp_relations_val, \n",
    "                                                          sources_val, targets_val, query_text_val)\n",
    "        best_model.eval()\n",
    "        q_loss = None\n",
    "        saved_loss = None\n",
    "        cnt_val = 0\n",
    "        val_loss = 0\n",
    "        cnt_break_val = 0\n",
    "        for first_pair, second_pair in zip(all_val_first_pair, all_val_second_pair):\n",
    "            \n",
    "            for idx in range(0, len(first_pair.x)):\n",
    "                pred_fp = best_model(first_pair.x_1_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "                    first_pair.attention_mask_1_tensors[idx].unsqueeze(0), first_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "                    first_pair.segment_id_2_tensors[idx].unsqueeze(0), first_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "                    first_pair.x_3_tokens_tensors[idx].unsqueeze(0), first_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "                    first_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "\n",
    "                pred_sp = best_model(second_pair.x_1_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_1_tensors[idx].unsqueeze(0),\\\n",
    "                    second_pair.attention_mask_1_tensors[idx].unsqueeze(0), second_pair.x_2_tokens_tensors[idx].unsqueeze(0),\\\n",
    "                    second_pair.segment_id_2_tensors[idx].unsqueeze(0), second_pair.attention_mask_2_tensors[idx].unsqueeze(0),\\\n",
    "                    second_pair.x_3_tokens_tensors[idx].unsqueeze(0), second_pair.segment_id_3_tensors[idx].unsqueeze(0),\\\n",
    "                    second_pair.attention_mask_3_tensors[idx].unsqueeze(0))\n",
    "                \n",
    "                if first_pair.scores[idx] > second_pair.scores[idx]:\n",
    "                    S_ij = 1\n",
    "                elif first_pair.scores[idx] == second_pair.scores[idx]:\n",
    "                    S_ij = 0\n",
    "                else:\n",
    "                    S_ij = -1 \n",
    "                \n",
    "                q_loss = pairwise_loss(pred_fp[0][0][0], pred_sp[0][0][0], S_ij)\n",
    "                q_loss = q_loss / len(all_val_first_pair)\n",
    "                val_loss += q_loss.item()\n",
    "#                 q_loss.backward()\n",
    "#                 if cnt_val == 0:\n",
    "#                     saved_loss = q_loss.clone()\n",
    "#                 else:\n",
    "#                     saved_loss += q_loss.clone()\n",
    "                \n",
    "#                 fast_model.zero_grad()\n",
    "#                 if cnt_break_val == 128:\n",
    "#                     break\n",
    "                cnt_val += 1  \n",
    "#                 cnt_break_val+=1\n",
    "            print(val_loss/cnt_val)\n",
    "                \n",
    "#         saved_loss /= cntcnt_train_val\n",
    "        \n",
    "#         saved_loss.backward()\n",
    "        \n",
    "#         fast_model.to(torch.device('cpu'))\n",
    "#         for i, params in enumerate(fast_model.parameters()):\n",
    "#             if first_task == False:\n",
    "#                 sum_gradients.append(deepcopy(params.grad))\n",
    "#             else:\n",
    "#                 sum_gradients[i] += deepcopy(params.grad)\n",
    "                        \n",
    "#         del fast_model, inner_optimizer, saved_loss\n",
    "#         torch.cuda.empty_cache()\n",
    "#         first_task = True\n",
    "#         num_task += 1\n",
    "# #         print(sum_gradients)\n",
    "        \n",
    "#     for i in range(0, len(sum_gradients)):\n",
    "#         print(\"before\")\n",
    "#         print(sum_gradients[i])\n",
    "#         print(\"after\")\n",
    "#         print(sum_gradients[i] / float(num_task))\n",
    "#         sum_gradients[i] = sum_gradients[i] / float(num_task)\n",
    "#     print(\"average\")\n",
    "#     print(sum_gradients)\n",
    "#     state_dict = best_model.state_dict()\n",
    "#     for n_p, i in zip(sum_gradients, state_dict):\n",
    "#         state_dict[i] = n_p\n",
    "#     best_model.load_state_dict(state_dict)\n",
    "        \n",
    "#     meta_learning_optimizer.step()\n",
    "#     best_model.zero_grad()\n",
    "        \n",
    "#     del sum_gradients\n",
    "#     gc.collect()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_results(best_model, 'meta_learned_bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in best_model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
